###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "assertions.baml": "// Defining a data model.\nclass Assertion {\n    Cardinal string[] @description(\"The main research question or proposed explanation the paper tests (e.g., Does X affect Y?).\")\n    Supporting  string[] @description(\"Evidence or reasoning backing the hypothesis, such as experimental data or cited studies.\")\n}\n\n// Create a function to extract the idea from a string.\nfunction ExtractAssertion(idea: string) -> Assertion {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  //client \"XAI\"                  // use xai\n  prompt #\"\n\nExtract the most significant Cardinal Assertions from the research paper.\n Cardinal Assertions are the novel, significant, or central claims that\n represent the core contribution of the research. These are often found\n in the abstract, introduction, results, and discussion sections and may\n use language such as \"we found that,\" \"our results show,\" or \"this study demonstrates.\"\n For example, a Cardinal Assertion might be: \"This study demonstrates that X leads to Y,\n challenging the previous understanding that Z is the primary factor.\"\n\nFor each Cardinal Assertion, list the corresponding Supporting Assertions that provide\ncontext, methodology, provenance, or evidence. Supporting Assertions are typically\nfound in the methods and introduction sections and may include phrases like \"using the method of,\"\n\"based on data from,\" or \"as defined by.\" For example, a Supporting Assertion might\nbe: \"The data was collected from a sample of 100 participants using a randomized controlled trial design.\"\n\nEnsure that all extracted assertions are directly supported by the text and do not\ninfer or generate information not explicitly stated in the research paper. If you do not find anything simply\n    do not repot for that elements, do not state that nothing is found.\n\n\n    {{ idea }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function Open the VSCode playground to run this.\ntest vaibhav_idea {\n  functions [ExtractAssertion]\n  args {\n    idea #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> XAI {\n  provider openai-generic\n  options {\n    model grok-3-mini-beta\n    base_url \"https://api.x.ai/v1\"\n    api_key env.XAI_API_KEY\n  }\n}\n\nclient<llm> CustomGemini {\n  provider google-ai\n  options {\n    model \"gemini-1.5-pro\"\n    api_key env.GEMINI_API_KEY\n  }\n}\n\nclient<llm> LocalQwen {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://192.168.202.88:11434/v1\"\n    model qwen2.5-coder:14b\n  }\n}\n\nclient<llm> LocalGemma {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://192.168.202.88:11434/v1\"\n    model gemma3:12b\n  }\n}\n\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.88.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "hypothesis.baml": "// Defining a data model.\nclass Idea {\n    hypothesis string[] @description(\"The main research question or proposed explanation the paper tests (e.g., Does X affect Y?).\")\n    supportingArguments  string[] @description(\"Evidence or reasoning backing the hypothesis, such as experimental data or cited studies.\")\n    researchOpportunities string[] @description(\"Areas for future research or gaps in knowledge suggested by the paper.\")\n    methodology string[] @description(\"How the research was conducted, including experimental design and techniques.\")\n    results string[] @description(\"The key outcomes or findings from the study.\")\n    conclusions string[] @description(\"The paperâ€™s final interpretations or decisions based on the results.\")\n    limitations string[] @description(\"Weaknesses or constraints in the study that might impact the findings.\")\n    futureDirections string[] @description(\"Specific suggestions for next steps in research, slightly distinct from research opportunities by being more actionable.\")\n    keyFindings string[] @description(\"The most significant or impactful results highlighted in the paper.\")\n    references string[] @description(\"Cited works that provide context or support for the study.\")\n}\n\n// Create a function to extract the idea from a string.\nfunction ExtractIdea(idea: string) -> Idea {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  //client \"XAI\"                  // use xai\n  prompt #\"\n\n    Instructions:\n    Analyze the provided text from a research paper and extract the\n    following elements. For each element, provide a concise summary or direct quote from the\n    text where possible. If an element is not explicitly stated,\n    indicate \"Not explicitly mentioned\" or infer it from the context if reasonable.\n    Organize your output with clear headings for each element.\n\n    Hypothesis\n    Identify the main hypothesis or research question the paper addresses. Look for statements like \"We hypothesize that...\" or \"This study aims to determine...\" in the introduction or abstract.\n\n    Supporting Argument\n    Extract key evidence or reasoning supporting the hypothesis, such as experimental data, observations, or references to prior studies. Check the results, discussion, or literature review sections.\n\n    Research Opportunities\n    Highlight areas suggested for further research or gaps in knowledge. Look for phrases like \"Future studies could explore...\" or \"This raises questions about...\" in the discussion or conclusion.\n\n    Methodology\n    Summarize the methods or techniques used to test the hypothesis, including experimental design, data collection, and analysis. Typically found in the \"Methods\" or \"Materials and Methods\" section.\n\n    Results\n    Describe the main findings or outcomes of the study, including quantitative data (e.g., measurements, statistics) or qualitative observations. Look in the \"Results\" section, tables, or figures.\n\n    Conclusions\n    Extract the final interpretations or decisions drawn from the research, such as whether the hypothesis was supported. Found in the \"Conclusion\" or \"Discussion\" section.\n\n    Limitations\n    Note any constraints, weaknesses, or biases mentioned that might affect the results. Look for phrases like \"A limitation of this study is...\" in the discussion.\n\n    Future Directions\n    Identify specific suggestions for future research based on the findings. Look for actionable recommendations like \"Future work should investigate...\" in the conclusion.\n\n    Key Findings\n    Highlight the most significant or impactful results emphasized by the authors. Check the abstract, conclusion, or discussion for standout points.\n\n    References\n    List key studies or papers cited in the text that provide context or support. Found in in-text citations or the reference list.\n\n    Ensure that all extracted elements are directly supported by the text and do not\n    infer or generate information not explicitly stated in the research paper.  If you do not find anything simply\n    do not repot for that elements, do not state that nothing is found.\n\n    {{ idea }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function Open the VSCode playground to run this.\ntest vaibhav_idea {\n  functions [ExtractIdea]\n  args {\n    idea #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
    "nanopub.baml": "// Defining a data model.\n\n// need enums for predicates   ref:  https://docs.boundaryml.com/ref/baml/enum    \n\nclass Nanograph {\n    triples Nanopub[]\n}\n\nclass Nanopub {\n    subject string  // @description(\"The main research question or proposed explanation the paper tests (e.g., Does X affect Y?).\")\n    predicate  string // @description(\"Evidence or reasoning backing the hypothesis, such as experimental data or cited studies.\")\n    object string // @description(\"Evidence or reasoning backing the hypothesis, such as experimental data or cited studies.\")\n}\n\n\n// Create a function to extract the idea from a string.\nfunction ExtractNanopubs(idea: string) -> Nanograph {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  //client \"XAI\"                  // use xai\n  prompt #\"\n\nYou are an expert in semantic web technologies and nanopublications. Your task is to analyze a given scientific text and extract the components of a nanopublication assertion, specifically the subject, predicate, and object, to form a structured assertion in the format of a subject-predicate-object triple. \n\n**Instructions:**\n1. Read the provided text carefully.\n2. Identify the core scientific claim or relationship described in the text.\n3. Extract:\n   - **Subject**: The entity or concept that the claim is about (e.g., a gene, drug, or disease).\n   - **Predicate**: The relationship or action connecting the subject and object (e.g., \"is associated with,\" \"inhibits,\" \"causes\").\n   - **Object**: The entity or concept that the subject is related to (e.g., another gene, disease, or outcome).\n4. Present the assertion as a clear subject-predicate-object triple.\n5. If the text is ambiguous or lacks a clear claim, state that no assertion could be formed and explain why.\n6. Do not include provenance or publication info unless explicitly requested.\n\n\nThere may be more than one assertion (set of triples) or none, in the provided text.\n\nIf the text has no assertions that can be found return the requested format with\nempty elements.\n\n**Example:**\n**Input Text**: \"The study found that Drug X effectively reduces symptoms of Disease Y.\"\n**Output**:\n- **Assertion**: Drug X - reduces symptoms of - Disease Y\n- **Explanation**: The subject is \"Drug X\" (the entity the claim is about), the predicate is \"reduces symptoms of\" (the relationship), and the object is \"Disease Y\" (the entity affected).\n\n    {{ idea }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function Open the VSCode playground to run this.\ntest vaibhav_idea {\n  functions [ExtractNanopubs]\n  args {\n    idea #\"\n    Our work uses CNNs trained with magnetic field vectors from analytical flux rope data.\n    The simulated flux ropes span many possible spacecraft trajectories and flux rope orientations.\n    The circular-cylindrical flux rope model of Nieves-Chinchilla et al. [19] (N-C model) is used to simulate the magnetic field signature of flux ropes.\n    The process of casting the physics problem as a machine learning problem is discussed.\n    Various physics-based flux rope models exist (for examples Lepping et al. [9]and Nieves-Chinchilla et al. [10]) that can be used to reconstruct the internal ICME magnetic configuration.\n    The neural network is trained using simulated magnetic field measurements over a range of spacecraft trajectories and flux rope orientations.\n    The final segment of this work is to evaluate the trained CNNs on flux ropes observed by the Wind spacecraft.\n    Figure 3. The parameter prediction error for the synthetic test set of full duration flux rope crossings\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return file_map